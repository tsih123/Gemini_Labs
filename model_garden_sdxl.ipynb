{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "7d9bbf86da5e"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "99c1c3fc2ca5"
   },
   "source": [
    "# Vertex AI Model Garden - Open Models (Stable Diffusion XL)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3de7470326a2"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates how you can call open models that are deployed on Vertex AI Prediction. The model used in this notebook is:\n",
    " * [Stable Diffusion XL]\n",
    "\n",
    "### Objective\n",
    "\n",
    "* Send requests to the Vertex AI Prediction Endpoint that is hosting Stable Diffusion 2.1\n",
    "\n",
    "\n",
    "### Assumptions\n",
    "- The model is already deployed via Model Garden's one-click deploy feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "264c07757582"
   },
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "Run the cell below if this is your first time running the notebook. Else, feel free to skip the cell below as the libraries would have already been installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --user --quiet google-cloud-aiplatform\n",
    "%pip install --quiet tensorflow\n",
    "! git clone https://github.com/GoogleCloudPlatform/vertex-ai-samples.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import os\n",
    "import uuid\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "common_util = importlib.import_module(\n",
    "    \"vertex-ai-samples.community-content.vertex_model_garden.model_oss.notebook_util.common_util\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set your project ID and region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the default cloud project id.\n",
    "PROJECT_ID= !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "print(f\"Project ID:\", PROJECT_ID)\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID)\n",
    "\n",
    "endpoints = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with Vertex AI Prediction Endpoints\n",
    "\n",
    "After you've deployed your target model to a Vertex AI Prediction Endpoint, you can send requests to the endpoint with text prompts based on your `template`. Note that the first few prompts will take longer to execute. \n",
    "\n",
    "First, let's retrieved the details of the endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the Vertex AI Prediction Endpoint IDs and set it\n",
    "check_regions = [\"us-central1\", \"asia-southeast1\", \"europe-west4\"]\n",
    "\n",
    "for region in check_regions:\n",
    "    all_endpoints = aiplatform.Endpoint.list(location=region)\n",
    "    for endpoint in all_endpoints:\n",
    "        full_endpoint = f\"projects/{PROJECT_ID}/locations/{region}/endpoints/{endpoint.name}\"\n",
    "        \n",
    "        if endpoint.display_name == \"stabilityai_stable-diffusion-xl-1-mg-one-click-deploy\":\n",
    "            endpoints['sdxl'] = aiplatform.Endpoint(full_endpoint)\n",
    "\n",
    "print(f\"Stable Diffusion XL Endpoint Name: {endpoints['sdxl'].display_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Images with Stable Diffusion XL\n",
    "\n",
    "After your model is deployed, you'll be able to generate images by sending text prompts to the endpoint. Try your hand at generating some images below! \n",
    "\n",
    "**Example:**\n",
    "```\n",
    "> A photo of an astronaut riding a horse on mars\n",
    "> A stone castle in a forest by the river\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create your prompts by adding them to a prompt list\n",
    "\n",
    "comma_separated_prompt_list = \"A photo of an astronaut riding a horse on mars, A stone castle in a forest by the river\"  # @param {type: \"string\"}\n",
    "prompt_list = [x.strip() for x in comma_separated_prompt_list.split(\",\")]\n",
    "\n",
    "# [Optional] Set a negative prompt to define what you don't want to see.\n",
    "negative_prompt = \"\"\n",
    "\n",
    "# Set parameters\n",
    "height = 768\n",
    "width = 768\n",
    "num_inference_steps = 25\n",
    "guidance_scale = 7.5\n",
    "\n",
    "\n",
    "# Construct instance list\n",
    "instances = [{\"text\": prompt} for prompt in prompt_list]\n",
    "parameters = {\n",
    "    \"negative_prompt\": negative_prompt,\n",
    "    \"height\": height,\n",
    "    \"width\": width,\n",
    "    \"num_inference_steps\": num_inference_steps,\n",
    "    \"guidance_scale\": 7.5,\n",
    "}\n",
    "\n",
    "# Send prompts and parameters to the endpoint\n",
    "response = endpoints['sdxl'].predict(\n",
    "    instances=instances, parameters=parameters\n",
    ")\n",
    "\n",
    "# Display the generated images\n",
    "images = [\n",
    "    common_util.base64_to_image(prediction.get(\"output\"))\n",
    "    for prediction in response.predictions\n",
    "]\n",
    "display(common_util.image_grid(images, rows=math.ceil(len(images) ** 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_garden_gemma2_deployment_on_vertex.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
